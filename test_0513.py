import streamlit as st
import json
import uuid
from datetime import datetime
import os
import pandas as pd
from openai import OpenAI
import traceback  # ì˜¤ë¥˜ ì¶”ì ìš©

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="ê¸°í›„ ìœ„ê¸° ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„± í™œë™ ë„ìš°ë¯¸",
    page_icon="ğŸŒ",
    layout="wide"
)

# API í‚¤ ì„¤ì • - í™˜ê²½ ë³€ìˆ˜ë‚˜ ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ìˆ˜ì •
# í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


# 2. í™˜ê²½ ë³€ìˆ˜ì— ì—†ìœ¼ë©´ Streamlit Secretsì—ì„œ ê°€ì ¸ì˜¤ê¸°
if not OPENAI_API_KEY:
    try:
        OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
    except Exception as e:
        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì—ì„œ 'OPENAI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        st.stop()

# 3. API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
if not OPENAI_API_KEY:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit Cloudì˜ Secretsì—ì„œ 'OPENAI_API_KEY'ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()
    
# í•™ìƒë³„ ìµœëŒ€ API í˜¸ì¶œ íšŸìˆ˜ ì„¤ì •
MAX_API_CALLS_PER_STUDENT = 50  # í•™ìƒë³„ ìµœëŒ€ API í˜¸ì¶œ íšŸìˆ˜

# í•™ìƒë³„ API í˜¸ì¶œ íšŸìˆ˜ ì¶”ì 
if "student_api_calls" not in st.session_state:
    st.session_state.student_api_calls = {}

# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ëª¨ë¸ ì„ íƒ ê°€ëŠ¥)
def get_gpt_response(messages, use_gpt4=False):
    student_id = st.session_state.student_id
    
    # í•™ìƒë³„ API í˜¸ì¶œ íšŸìˆ˜ ì´ˆê¸°í™”
    if student_id not in st.session_state.student_api_calls:
        st.session_state.student_api_calls[student_id] = 0
    
    # API í˜¸ì¶œ íšŸìˆ˜ ì œí•œ í™•ì¸
    if st.session_state.student_api_calls[student_id] >= MAX_API_CALLS_PER_STUDENT:
        return "API í˜¸ì¶œ íšŸìˆ˜ê°€ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì„ ìƒë‹˜ì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
    
    # ê°„ë‹¨í•œ ìºì‹±ì„ ìœ„í•œ í‚¤ ìƒì„± (ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ê³ ë ¤)
    cache_key = str([msg for msg in messages if msg["role"] == "user"]) + str(use_gpt4)
    
    # ìºì‹œëœ ì‘ë‹µì´ ìˆëŠ”ì§€ í™•ì¸
    if cache_key in st.session_state.response_cache:
        return st.session_state.response_cache[cache_key]
    
    try:
        # API í˜¸ì¶œ ì¹´ìš´í„° ì¦ê°€
        st.session_state.api_call_count += 1
        st.session_state.student_api_calls[student_id] += 1
        
        # ëª¨ë¸ ì„ íƒ
        model = FEEDBACK_MODEL if use_gpt4 else DEFAULT_MODEL
        
        api_params = {
            "model": model,
            "messages": messages
        }
        # o1 ëª¨ë¸ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ temperature ì¶”ê°€
        if not model.startswith("o1"):
            api_params["temperature"] = 0.7
            response = client.chat.completions.create(**api_params)
        
        response_text = response.choices[0].message.content
        
        # ì‘ë‹µ ìºì‹±
        st.session_state.response_cache[cache_key] = response_text
        
        return response_text
    except Exception as e:
        st.error(f"GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
# GPTë¥¼ í™œìš©í•œ ë©”ì‹œì§€ ê´€ë ¨ì„± ë¶„ì„ í•¨ìˆ˜ë“¤ (get_gpt_response í•¨ìˆ˜ ì•„ë˜ì— ì¶”ê°€)

def analyze_message_relevance(message_content):
    """GPTë¥¼ ì‚¬ìš©í•´ì„œ ë©”ì‹œì§€ê°€ ìŠ¤í† ë¦¬ë³´ë“œ ê´€ë ¨ì¸ì§€ íŒë‹¨"""
    
    analysis_prompt = f"""
    ë‹¤ìŒ í•™ìƒì˜ ë©”ì‹œì§€ê°€ ê¸°í›„ ìœ„ê¸° ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±ê³¼ ê´€ë ¨ëœ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.
    
    í•™ìƒ ë©”ì‹œì§€: "{message_content}"
    
    ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•´ì£¼ì„¸ìš”:
    
    ê´€ë ¨ëœ ë‚´ìš©:
    - ìŠ¤í† ë¦¬ë³´ë“œ ì£¼ì œ, êµ¬ì„±, ìºë¦­í„°, ì¥ë©´ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì•„ì´ë””ì–´
    - ê¸°í›„ ìœ„ê¸° ê´€ë ¨ ë‚´ìš© ë¬¸ì˜ ë° í† ë¡ 
    - ì°½ì‘ ê³¼ì •ì—ì„œì˜ êµ¬ì²´ì ì¸ ê³ ë¯¼ì´ë‚˜ ìš”ì²­
    - ìŠ¤í† ë¦¬ë³´ë“œ ì œì‘ ë°©ë²•ì— ëŒ€í•œ ì§ˆë¬¸
    - ë°œí‘œ ì¤€ë¹„ë‚˜ í”¼ë“œë°± ìš”ì²­
    - êµ¬ì²´ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë‚˜ ìƒí™© ì„¤ì •ì— ëŒ€í•œ ë…¼ì˜
    
    ê´€ë ¨ì—†ëŠ” ë‚´ìš©:
    - ë‹¨ìˆœ ì¸ì‚¬ë§ ("ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ë„¤", "ì¢‹ì•„ìš”")
    - ìˆ˜í–‰í‰ê°€ì™€ ë¬´ê´€í•œ ì¡ë‹´ì´ë‚˜ ê°œì¸ì ì¸ ì´ì•¼ê¸°
    - ë„ˆë¬´ ì§§ê±°ë‚˜ ì˜ë¯¸ì—†ëŠ” ì‘ë‹µ ("ëª°ë¼ìš”", "ìŒ", "ì–´")
    - ë‹¨ìˆœ í™•ì¸ ì‘ë‹µ ("ì•Œê² ìŠµë‹ˆë‹¤", "ë„¤ ë§ì•„ìš”")
    
    ë‹µë³€: "ê´€ë ¨ë¨" ë˜ëŠ” "ê´€ë ¨ì—†ìŒ" ì¤‘ í•˜ë‚˜ë§Œ ì •í™•íˆ ë‹µí•˜ì„¸ìš”.
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": analysis_prompt}],
            temperature=0.1,  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
        )
        
        result = response.choices[0].message.content.strip()
        return "ê´€ë ¨ë¨" in result
    except Exception as e:
        # API ì˜¤ë¥˜ ì‹œ ë³´ìˆ˜ì ìœ¼ë¡œ ê´€ë ¨ë¨ìœ¼ë¡œ ì²˜ë¦¬ (í•™ìƒì—ê²Œ ë¶ˆì´ìµ ë°©ì§€)
        print(f"ë©”ì‹œì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return True

def count_relevant_prompts(conversation):
    """ëŒ€í™”ì—ì„œ ìŠ¤í† ë¦¬ë³´ë“œ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜ ê³„ì‚°"""
    relevant_count = 0
    
    for msg in conversation["messages"]:
        if msg["role"] == "user":
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë‚˜ ì›°ì»´ ë©”ì‹œì§€ì— ëŒ€í•œ ë‹¨ìˆœ ì‘ë‹µì€ ì œì™¸
            if len(msg["content"].strip()) < 3:
                continue
                
            if analyze_message_relevance(msg["content"]):
                relevant_count += 1
    
    return relevant_count

def analyze_conversations_with_gpt(conversations, progress_callback=None):
    """ì—¬ëŸ¬ ëŒ€í™”ë¥¼ GPTë¡œ ë¶„ì„ (ì§„í–‰ ìƒí™© í‘œì‹œ í¬í•¨)"""
    analyzed_data = []
    total = len(conversations)
    
    for i, conv in enumerate(conversations):
        if progress_callback:
            progress_callback(i + 1, total)
            
        student_name = conv["student_name"]
        student_id = conv["student_id"]
        
        # GPTë¡œ ê´€ë ¨ ë©”ì‹œì§€ ìˆ˜ ë¶„ì„
        relevant_count = count_relevant_prompts(conv)
        total_user_messages = sum(1 for msg in conv["messages"] if msg["role"] == "user")
        assistant_msg_count = sum(1 for msg in conv["messages"] if msg["role"] == "assistant")
        
        # ëŒ€í™” ì‹œê°„ ê³„ì‚°
        if conv["messages"]:
            first_msg_time = datetime.strptime(conv["messages"][0]["timestamp"], "%Y-%m-%d %H:%M:%S")
            last_msg_time = datetime.strptime(conv["messages"][-1]["timestamp"], "%Y-%m-%d %H:%M:%S")
            duration = (last_msg_time - first_msg_time).total_seconds() / 60
        else:
            duration = 0
        
        # í”¼ë“œë°± ì—¬ë¶€ í™•ì¸
        has_feedback = "feedback" in conv and len(conv["feedback"]) > 0
        
        analyzed_data.append({
            "í•™ìƒëª…": student_name,
            "í•™ë²ˆ": student_id,
            "ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜": relevant_count,
            "ì „ì²´ ë©”ì‹œì§€ ìˆ˜": total_user_messages,
            "AI ì‘ë‹µ ìˆ˜": assistant_msg_count,
            "ê´€ë ¨ë„": f"{relevant_count}/{total_user_messages}" if total_user_messages > 0 else "0/0",
            "ëŒ€í™” ì‹œê°„(ë¶„)": round(duration, 1),
            "í”¼ë“œë°± ì—¬ë¶€": "O" if has_feedback else "X"
        })
    
    return analyzed_data
    
# ë°ì´í„° ì €ì¥ ê²½ë¡œ ì„¤ì •
DATA_DIR = "data"
CONVERSATIONS_DIR = os.path.join(DATA_DIR, "conversations")
STUDENTS_FILE = os.path.join(DATA_DIR, "students.json")

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CONVERSATIONS_DIR, exist_ok=True)

# í•™ìƒ ì •ë³´ íŒŒì¼ ì´ˆê¸°í™”
if not os.path.exists(STUDENTS_FILE):
    with open(STUDENTS_FILE, 'w', encoding='utf-8') as f:
        json.dump([], f)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ìƒì„±)
client = OpenAI(api_key=OPENAI_API_KEY)

# ëª¨ë¸ ì„¤ì • (GPT-04-mini ë˜ëŠ” GPT-4o)
DEFAULT_MODEL = "gpt-o4-mini"  # ê¸°ë³¸ ëª¨ë¸
FEEDBACK_MODEL = "gpt-4o"  # í”¼ë“œë°±ì— ì‚¬ìš©í•  ëª¨ë¸

# ì„¸ì…˜ ID ìƒì„± (ì²˜ìŒ ì•± ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ)
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({
        "role": "system",
        "content": """í•™ìƒë“¤ì˜ ìˆ˜í–‰í‰ê°€ë¥¼ ë„ì›€ì„ ì£¼ê¸°ìœ„í•œ ëŒ€í™”ë¥¼ í•˜ë ¤ê³  í•˜ëŠ”ë°, ì—­í• , ë§íˆ¬, í•µì‹¬ ì£¼ì œ, ìˆ˜í–‰í‰ê°€ ë‹¨ê³„, ì œí•œì‚¬í•­, ì°¸ê³ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”. 
        # ì—­í•  : ì¤‘í•™êµ 3í•™ë…„ í•™ìƒë“¤ì´ ê¸°í›„ ìœ„ê¸° ê´€ë ¨ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ë•ëŠ” ì¡°ìˆ˜
        # ë§íˆ¬ : í•™ìƒë“¤ì—ê²Œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¡œ ì‘ë‹µ
        # í•µì‹¬ ì£¼ì œ
        ## ê¸°í›„ìœ„ê¸°
        ### ì†Œë¹„ëŠ” íƒ„ì†Œ ë°œìêµ­ì„ ë‚¨ê¸´ë‹¤
        - **ìŠ¤ë§ˆíŠ¸í°ê³¼ ìì› ì†Œë¹„**: ìŠ¤ë§ˆíŠ¸í° ìƒì‚°ì— 40ì—¬ ê°€ì§€ ê´‘ë¬¼ì´ ì‚¬ìš©ë˜ë©°, í‰ê·  êµì²´ ì£¼ê¸°ëŠ” 2.7ë…„
        - **ë°ì´í„° ì„¼í„°ì˜ í™˜ê²½ ì˜í–¥**: ì „ ì„¸ê³„ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œì˜ 2%ê°€ ë°ì´í„° ì„¼í„°ì—ì„œ ë°œìƒ
        - **í”Œë¼ìŠ¤í‹± ë¬¸ì œ**: 1950ë…„ 200ë§Œí†¤ ìƒì‚°ì—ì„œ 2015ë…„ 4ì–µ 7000ë§Œí†¤ìœ¼ë¡œ ì¦ê°€
        - **íŒ¨ìŠ¤íŠ¸ íŒ¨ì…˜ì˜ ì˜í–¥**: 2000ë…„ 500ì–µë²Œì—ì„œ 2015ë…„ 1000ì–µë²Œë¡œ íŒë§¤ëŸ‰ ì¦ê°€

        ### ìš°ë¦¬ê°€ ë¨¹ëŠ” ê²ƒ í•˜ë‚˜í•˜ë‚˜ê°€
        - **ê³ ê¸° ì†Œë¹„ì™€ í™˜ê²½**: ì¶•ì‚°ì—…ì€ ì§ì ‘ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œì˜ 18%, ê°„ì ‘ í¬í•¨ ì‹œ 30% ì°¨ì§€
        - **ì´ˆì½œë¦¿ê³¼ ì¹´ì¹´ì˜¤ ì¬ë°°**: ì§€ë‚œ 50ë…„ê°„ ì½”íŠ¸ë””ë¶€ì•„ë¥´ ìˆ²ì˜ 80%ê°€ ì‚¬ë¼ì§
        - **ìƒˆìš° ì–‘ì‹ê³¼ ë§¹ê·¸ë¡œë¸Œ ìˆ²**: ë§¹ê·¸ë¡œë¸Œ ìˆ²ì€ íƒ„ì†Œ í¡ìˆ˜ë ¥ì´ ì—´ëŒ€ìš°ë¦¼ì˜ 2.5ë°°ì´ë‚˜ ìƒˆìš° ì–‘ì‹ìœ¼ë¡œ íŒŒê´´ë¨
        - **ìŒì‹ë¬¼ ì“°ë ˆê¸°**: ìƒì‚°ëœ ìŒì‹ì˜ 1/3ì€ ë¨¹ê¸°ë„ ì „ì— ë²„ë ¤ì§

        ### ë‚¨ê·¹ì´ í­ê·„ì„ ìƒê²Œ ë  ë•Œ
        - **ë¶ê·¹ ë¹™í•˜**: 30ë…„ê°„ ë¶ê·¹ ë¹™í•˜ 50%ê°€ ê°ì†Œ, 2035ë…„ì—ëŠ” í•´ë¹™ì´ ì—†ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
        - **ì˜êµ¬ë™í† ì¸µ ìœµí•´**: ë©”íƒ„ ë°œìƒê³¼ ê°ì—¼ë³‘ í™•ì‚° ìœ„í—˜
        - **ë‚¨ê·¹ ê¸°ì˜¨ ìƒìŠ¹**: ìµœê·¼ 50ë…„ê°„ 3ë„ ìƒìŠ¹í•˜ì—¬ í­ê·„ ì„œì‹ì— ìœ„í˜‘
        - **ë¬¼ ìˆœí™˜ ë¬¸ì œ**: ê°€ë­„ê³¼ í­ìš°ì˜ ë°˜ë³µìœ¼ë¡œ ìˆ˜ìì› ìœ„ê¸°

        ### ê¸°í›„ìœ„ê¸°ì— ëŒ€ì‘í•˜ëŠ” ìš°ë¦¬ì˜ ì‹¤ì²œ
        - **í™”ì„ì—°ë£Œ ê¸°ì—…ì˜ ì˜í–¥**: ìµœê·¼ 50ë…„ê°„ ì „ ì„¸ê³„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì˜ 35% ì°¨ì§€
        - **ì¹œí™˜ê²½ êµí†µ**: ìì „ê±° ì¹œí™” ë„ì‹œì˜ í™•ì‚°ê³¼ ê³µìœ  ì°¨ëŸ‰ ì‹œìŠ¤í…œ
        - **ì¬ìƒì—ë„ˆì§€ í™•ëŒ€**: í™”ì„ì—°ë£Œ ì¤‘ì‹¬ì—ì„œ ì¬ìƒì—ë„ˆì§€ ì¤‘ì‹¬ ì „í™˜ í•„ìš”
        - **ì§€ì†ê°€ëŠ¥í•œ ìƒí™œë°©ì‹**: ë¼ë²¨ ì—†ëŠ” ìƒí’ˆ, í…€ë¸”ëŸ¬ ê³µìœ  ì„œë¹„ìŠ¤ ë“± ìƒˆë¡œìš´ ì‹œë„
        
        # ìˆ˜í–‰í‰ê°€ ë‹¨ê³„
        1. ëª¨ë‘ ë³„ í™œë™(ìŠ¤í† ë¦¬ë³´ë“œ ì£¼ì œ ì„ ì •)
        * ë„“ì€ ì£¼ì œì˜ ì£¼ì œë³´ë‹¤ëŠ” ì¢ì€ ë²”ìœ„ì˜ ì£¼ì œ ì„ ì •(ì˜ˆ: ë°ì´í„° ì„¼í„° â†’ ë°ì´í„° ì„¼í„°ì˜ ìœ„ì¹˜, ë§¹ê·¸ë¡œë¸Œ ìˆ² â†’ ë§¹ê·¸ë¡œë¸Œ ìˆ²ì˜ ì˜í–¥)
        * ì£¼ì œë¥¼ ì˜ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œëŠ” ëª‡ ì¥ì˜ ìŠ¤í† ë¦¬ë³´ë“œê°€ ì ì ˆí•œì§€ ê²°ì •
        * ëª¨ë‘ ì›ë“¤ì´ ê³µìœ í•´ì•¼ í•˜ëŠ” ìŠ¤í† ë¦¬ë³´ë“œì˜ ì „ì²´ ë¶„ìœ„ê¸° ë° ë“±ì¥ì¸ë¬¼, ë°°ê²½ë“± ë¯¸ë¦¬ ì •í•˜ê¸°
        2. ê°œì¸ë³„ ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±
        * ëª¨ë‘ ì˜ ìŠ¤í† ë¦¬ë³´ë“œ ì¤‘ì—ì„œ ì—­í•  ë¶„ë‹´ë°›ì€ íŠ¹ì • ì¥ë©´ì˜ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ë§Œë“¤ê¸°
        * íŠ¹ì • ì¥ë©´ì„ í‘œí˜„í•˜ê¸° ìœ„í•œ ëª‡ ê°€ì§€ ì»· ë§Œë“¤ê¸°
        * ê° ì»·ì˜ ë¹„ë””ì˜¤(ì´ë¯¸ì§€)ì™€ í•´ë‹¹ ì»·ì˜ ì„¤ëª…, ëŒ€ëµì ì¸ ì†Œìš”ì‹œê°„ í‘œí˜„í•˜ê¸°
        3. ë°œí‘œ
        * ëª¨ë‘ ì—ì„œ ì‘ì„±í•œ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ í•œ ëª…ì´ ë°œí‘œ
        * ë°œí‘œì‹œì— ì–´ë– í•œ ì£¼ì œë¥¼ ì–´ë– í•œ ë¶„ìœ„ê¸°ì—ì„œ ì–´ë–¤ ì¸ë¬¼ì´ ì–´ë–»ê²Œ í–ˆë‹¤ëŠ” ê²ƒì„ í‘œí˜„
        # ì œí•œì‚¬í•­
        * ìˆ˜í–‰í‰ê°€ì„ì„ ë¶„ëª…íˆ í•˜ê³  ëŒ€í™”ì—ì„œ ìˆ˜í–‰í‰ê°€ì™€ ê´€ë ¨ì—†ëŠ” ëŒ€í™”ê°€ ì‹¤ì‹œë  ê²½ìš°ì—ëŠ” ê°ì ì´ ë  ìˆ˜ ìˆìŒ.
        * ìˆ˜í–‰í‰ê°€ ê´€ë ¨ ëŒ€í™”ê°€ ì•„ë‹Œ ëŒ€í™”ë¥¼ 3ë²ˆ ì—°ì†í•´ì„œ ì§„í–‰í•  ì‹œì— ê²½ê³ í•˜ê¸°.
        # ì°¸ê³ ì‚¬í•­
        1. ëª¨ë‘  êµ¬ì„± : 3 ~ 4ëª…
        2. í•™ìƒë“¤ì€ ìˆ˜í–‰í‰ê°€ ë‹¨ê³„1, ë‹¨ê³„2, ë‹¨ê³„3 ì—ì„œ ë„ì›€ ìš”ì²­ ì˜ˆì •
        3. ìš”ì²­í•˜ëŠ” ë‹¨ê³„ë¥¼ ì´í•´í•œí›„ ëŒ€ë‹µ ìš”êµ¬
        4. ì°½ì˜ì ì´ê³  íš¨ê³¼ì ì¸ ìŠ¤í† ë¦¬ë³´ë“œ ì œì‘í•˜ê¸° ìœ„í•´ ë„ì›€ì„ ì¤Œ"""
    })

# í•™ìƒ ì •ë³´ ìƒíƒœ ì´ˆê¸°í™”
if "student_info_submitted" not in st.session_state:
    st.session_state.student_info_submitted = False

# í”¼ë“œë°± ëª¨ë“œ ìƒíƒœ ì´ˆê¸°í™”
if "feedback_mode" not in st.session_state:
    st.session_state.feedback_mode = False

# API ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
if "api_call_count" not in st.session_state:
    st.session_state.api_call_count = 0

# ìºì‹± ì„¤ì •
if "response_cache" not in st.session_state:
    st.session_state.response_cache = {}


# í•™ìƒ ì •ë³´ ì €ì¥
def save_student_info(data):
    try:
        # ê¸°ì¡´ í•™ìƒ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
        with open(STUDENTS_FILE, 'r', encoding='utf-8') as f:
            students = json.load(f)

        # ìƒˆ í•™ìƒ ì •ë³´ ì¶”ê°€
        students.append(data)

        # ì—…ë°ì´íŠ¸ëœ ì •ë³´ ì €ì¥
        with open(STUDENTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(students, f, ensure_ascii=False, indent=2)

        return True
    except Exception as e:
        st.error(f"í•™ìƒ ì •ë³´ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


# ëŒ€í™” ì €ì¥ - íŒŒì¼ëª… í˜•ì‹ ë³€ê²½: í•™ë²ˆ_ì´ë¦„.json
def save_conversation(data):
    student_id = data["student_id"]
    student_name = data["student_name"]
    # íŒŒì¼ëª… í˜•ì‹ ë³€ê²½
    filename = f"{student_id}_{student_name}.json"
    conversation_file = os.path.join(CONVERSATIONS_DIR, filename)

    try:
        # ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
        if os.path.exists(conversation_file):
            with open(conversation_file, 'r', encoding='utf-8') as f:
                conversation = json.load(f)
        else:
            conversation = {
                "session_id": data["session_id"],
                "student_name": student_name,
                "student_id": student_id,
                "messages": []
            }

        # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
        message = {
            "role": data["type"].split("_")[0],  # "user" ë˜ëŠ” "assistant"
            "content": data["content"],
            "timestamp": data["timestamp"]
        }
        conversation["messages"].append(message)

        # ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ì €ì¥
        with open(conversation_file, 'w', encoding='utf-8') as f:
            json.dump(conversation, f, ensure_ascii=False, indent=2)

        return True
    except Exception as e:
        st.error(f"ëŒ€í™” ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


# í”¼ë“œë°± ì €ì¥ - íŒŒì¼ëª… í˜•ì‹ ë³€ê²½: í•™ë²ˆ_ì´ë¦„.json
def save_feedback(data):
    student_id = data["student_id"]
    student_name = data["student_name"]
    # íŒŒì¼ëª… í˜•ì‹ ë³€ê²½
    filename = f"{student_id}_{student_name}.json"
    conversation_file = os.path.join(CONVERSATIONS_DIR, filename)

    try:
        # ê¸°ì¡´ ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸°
        if os.path.exists(conversation_file):
            with open(conversation_file, 'r', encoding='utf-8') as f:
                conversation = json.load(f)

            # í”¼ë“œë°± ì¶”ê°€
            if "feedback" not in conversation:
                conversation["feedback"] = []

            feedback = {
                "content": data["content"],
                "timestamp": data["timestamp"]
            }
            conversation["feedback"].append(feedback)

            # ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ì €ì¥
            with open(conversation_file, 'w', encoding='utf-8') as f:
                json.dump(conversation, f, ensure_ascii=False, indent=2)

            return True
        else:
            st.error(f"ëŒ€í™” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {conversation_file}")
            return False
    except Exception as e:
        st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False


# ë°ì´í„° ì €ì¥ í•¨ìˆ˜
def save_data(data):
    if data["type"] == "student_info":
        return save_student_info(data)
    elif data["type"] == "feedback":
        return save_feedback(data)
    else:  # user_message ë˜ëŠ” assistant_message
        return save_conversation(data)


# GPT API í˜¸ì¶œ í•¨ìˆ˜ (ëª¨ë¸ ì„ íƒ ê°€ëŠ¥)
def get_gpt_response(messages, use_gpt4=False):
    # ê°„ë‹¨í•œ ìºì‹±ì„ ìœ„í•œ í‚¤ ìƒì„± (ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ê³ ë ¤)
    cache_key = str([msg for msg in messages if msg["role"] == "user"]) + str(use_gpt4)

    # ìºì‹œëœ ì‘ë‹µì´ ìˆëŠ”ì§€ í™•ì¸
    if cache_key in st.session_state.response_cache:
        return st.session_state.response_cache[cache_key]

    try:
        # API í˜¸ì¶œ ì¹´ìš´í„° ì¦ê°€
        st.session_state.api_call_count += 1

        # ëª¨ë¸ ì„ íƒ
        model = FEEDBACK_MODEL if use_gpt4 else DEFAULT_MODEL

        # API í˜¸ì¶œ
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.7,
        )

        response_text = response.choices[0].message.content

        # ì‘ë‹µ ìºì‹±
        st.session_state.response_cache[cache_key] = response_text

        return response_text
    except Exception as e:
        st.error(f"GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."


# ì‚¬ì´ë“œë°” - ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„± ê°€ì´ë“œ
with st.sidebar:
    st.title("ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„± ê°€ì´ë“œ")
    st.markdown("""
    ### ìŠ¤í† ë¦¬ë³´ë“œë€?
    ìŠ¤í† ë¦¬ë³´ë“œëŠ” ì´ì•¼ê¸°ì˜ íë¦„ì„ ì‹œê°ì ìœ¼ë¡œ ê³„íší•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ê¸°í›„ ìœ„ê¸°ì— ê´€í•œ 
    ì—¬ëŸ¬ë¶„ì˜ ìƒê°ê³¼ ì•„ì´ë””ì–´ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

    ### íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì‘ì„±ë²•
    1. **êµ¬ì²´ì ì¸ ìƒí™© ì„¤ì •í•˜ê¸°**: "í”¼ì ê°€ê²Œì—ì„œ ìƒˆìš°ê°€ í† í•‘ìœ¼ë¡œ ì˜¬ë¼ê°„ í”¼ìë¥¼ ë¨¹ìœ¼ë©´ì„œ ì¹œêµ¬ë“¤ê³¼ ì´ì•¼ê¸° ì¤‘ì¸ ìƒí™©ì„ ê·¸ë¦°ë‹¤ë©´?"
    2. **ì¸ë¬¼ê³¼ ê°ì • ì¶”ê°€í•˜ê¸°**: "ìƒˆìš°ë¥¼ ë¨¹ë‹¤ê°€ ë§¹ê·¸ë¡œë¸Œ ìˆ²ì´ ì‚¬ë¼ì ¸ ê°„ë‹¤ëŠ” ê²ƒì„ ì•Œê²Œëœ í›„ í”¼ìë¥¼ ë¨¹ì„ ë•Œ ëŠë¼ëŠ” ê°ì •ì€?"
    3. **ë¬¸ì œ í•´ê²° ë°©ì‹ íƒìƒ‰í•˜ê¸°**: "ë§¹ê·¸ë¡œë¸Œ ìˆ²ì´ ì‚¬ë¼ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ì„œëŠ” ë­˜ í•´ì•¼í• ê¹Œ?"
    4. **ëŒ€ë¹„ í™œìš©í•˜ê¸°**: "í˜„ì¬ì™€ ë§¹ê·¸ë¡œë¸Œ ìˆ²ì´ ì‚¬ë¼ì§„ ë¯¸ë˜ì˜ í™˜ê²½ì„ ëŒ€ë¹„í•˜ì—¬ ë³´ì—¬ì¤€ë‹¤ë©´?"
    5. **ì§€ì—­ íŠ¹ì„± ë°˜ì˜í•˜ê¸°**: "ìš°ë¦¬ ì§€ì—­ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ê¸°í›„ ë³€í™”ì˜ ì‹ í˜¸ëŠ”?"

    ### í‰ê°€ ê¸°ì¤€
    #### ìŠ¤í† ë¦¬ë³´ë“œ í‰ê°€ (40ì )
    - **Aë“±ê¸‰ (40ì )**: 5ê°œ ì´ìƒì˜ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ë©´ì„œ ê¸°ì¡´ì˜ ë¬¸ì œì ì„ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•¨
    - **Bë“±ê¸‰ (35ì )**: 4ê°œì˜ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ë©´ì„œ ê¸°ì¡´ì˜ ë¬¸ì œì ì„ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ê°œì„ í•¨
    - **Cë“±ê¸‰ (30ì )**: 3ê°œì˜ íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ë©´ì„œ ë¬¸ì œì  íŒŒì•…ê³¼ ê°œì„ ì´ ëŒ€ì²´ì ìœ¼ë¡œ ì²´ê³„ì 
    - **Dë“±ê¸‰ (25ì )**: 2ê°œì˜ ê¸°ë³¸ì ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±
    - **Eë“±ê¸‰ (20ì )**: 1ê°œì˜ ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©

    #### ë°œí‘œ í‰ê°€ (20ì )
    - **Aë“±ê¸‰ (20ì )**: í•µì‹¬ ë©”ì‹œì§€ë¥¼ ê¸°í›„ ìœ„ê¸°ì™€ ê´€ë ¨ì§€ì–´ ëª…í™•í•˜ê²Œ ë°œí‘œ
    - **Bë“±ê¸‰ (15ì )**: í•µì‹¬ ë©”ì‹œì§€ë¥¼ ê¸°í›„ ìœ„ê¸°ì™€ ê´€ë ¨ì§€ì—ˆì§€ë§Œ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ì§€ ì•ŠìŒ
    - **Cë“±ê¸‰ (10ì )**: í•µì‹¬ ë©”ì‹œì§€ë¥¼ ê¸°í›„ ìœ„ê¸°ì™€ ê´€ë ¨ì§“ì§€ ì•Šê³  ë°œí‘œ
    """)

    # í”¼ë“œë°± ë°›ê¸° ë²„íŠ¼
    if st.button("ë‚´ ìŠ¤í† ë¦¬ë³´ë“œ í”¼ë“œë°± ë°›ê¸°"):
        if len([m for m in st.session_state.messages if m["role"] == "user"]) > 0:
            st.session_state.feedback_mode = True
            st.rerun()
        else:
            st.warning("ë¨¼ì € ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±ì„ ìœ„í•œ ëŒ€í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # ì±… ë‚´ìš© ìš”ì•½ í™•ì¥ ì„¹ì…˜
    with st.expander("ğŸ“š í•„ë…ì„œ ë‚´ìš© ìš”ì•½"):
        st.markdown("""
        ### ì†Œë¹„ëŠ” íƒ„ì†Œ ë°œìêµ­ì„ ë‚¨ê¸´ë‹¤
        - **ìŠ¤ë§ˆíŠ¸í°ê³¼ ìì› ì†Œë¹„**: ìŠ¤ë§ˆíŠ¸í° ìƒì‚°ì— 40ì—¬ ê°€ì§€ ê´‘ë¬¼ì´ ì‚¬ìš©ë˜ë©°, í‰ê·  êµì²´ ì£¼ê¸°ëŠ” 2.7ë…„
        - **ë°ì´í„° ì„¼í„°ì˜ í™˜ê²½ ì˜í–¥**: ì „ ì„¸ê³„ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œì˜ 2%ê°€ ë°ì´í„° ì„¼í„°ì—ì„œ ë°œìƒ
        - **í”Œë¼ìŠ¤í‹± ë¬¸ì œ**: 1950ë…„ 200ë§Œí†¤ ìƒì‚°ì—ì„œ 2015ë…„ 4ì–µ 7000ë§Œí†¤ìœ¼ë¡œ ì¦ê°€
        - **íŒ¨ìŠ¤íŠ¸ íŒ¨ì…˜ì˜ ì˜í–¥**: 2000ë…„ 500ì–µë²Œì—ì„œ 2015ë…„ 1000ì–µë²Œë¡œ íŒë§¤ëŸ‰ ì¦ê°€

        ### ìš°ë¦¬ê°€ ë¨¹ëŠ” ê²ƒ í•˜ë‚˜í•˜ë‚˜ê°€
        - **ê³ ê¸° ì†Œë¹„ì™€ í™˜ê²½**: ì¶•ì‚°ì—…ì€ ì§ì ‘ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œì˜ 18%, ê°„ì ‘ í¬í•¨ ì‹œ 30% ì°¨ì§€
        - **ì´ˆì½œë¦¿ê³¼ ì¹´ì¹´ì˜¤ ì¬ë°°**: ì§€ë‚œ 50ë…„ê°„ ì½”íŠ¸ë””ë¶€ì•„ë¥´ ìˆ²ì˜ 80%ê°€ ì‚¬ë¼ì§
        - **ìƒˆìš° ì–‘ì‹ê³¼ ë§¹ê·¸ë¡œë¸Œ ìˆ²**: ë§¹ê·¸ë¡œë¸Œ ìˆ²ì€ íƒ„ì†Œ í¡ìˆ˜ë ¥ì´ ì—´ëŒ€ìš°ë¦¼ì˜ 2.5ë°°ì´ë‚˜ ìƒˆìš° ì–‘ì‹ìœ¼ë¡œ íŒŒê´´ë¨
        - **ìŒì‹ë¬¼ ì“°ë ˆê¸°**: ìƒì‚°ëœ ìŒì‹ì˜ 1/3ì€ ë¨¹ê¸°ë„ ì „ì— ë²„ë ¤ì§

        ### ë‚¨ê·¹ì´ í­ê·„ì„ ìƒê²Œ ë  ë•Œ
        - **ë¶ê·¹ ë¹™í•˜**: 30ë…„ê°„ ë¶ê·¹ ë¹™í•˜ 50%ê°€ ê°ì†Œ, 2035ë…„ì—ëŠ” í•´ë¹™ì´ ì—†ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
        - **ì˜êµ¬ë™í† ì¸µ ìœµí•´**: ë©”íƒ„ ë°œìƒê³¼ ê°ì—¼ë³‘ í™•ì‚° ìœ„í—˜
        - **ë‚¨ê·¹ ê¸°ì˜¨ ìƒìŠ¹**: ìµœê·¼ 50ë…„ê°„ 3ë„ ìƒìŠ¹í•˜ì—¬ í­ê·„ ì„œì‹ì— ìœ„í˜‘
        - **ë¬¼ ìˆœí™˜ ë¬¸ì œ**: ê°€ë­„ê³¼ í­ìš°ì˜ ë°˜ë³µìœ¼ë¡œ ìˆ˜ìì› ìœ„ê¸°

        ### ê¸°í›„ìœ„ê¸°ì— ëŒ€ì‘í•˜ëŠ” ìš°ë¦¬ì˜ ì‹¤ì²œ
        - **í™”ì„ì—°ë£Œ ê¸°ì—…ì˜ ì˜í–¥**: ìµœê·¼ 50ë…„ê°„ ì „ ì„¸ê³„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì˜ 35% ì°¨ì§€
        - **ì¹œí™˜ê²½ êµí†µ**: ìì „ê±° ì¹œí™” ë„ì‹œì˜ í™•ì‚°ê³¼ ê³µìœ  ì°¨ëŸ‰ ì‹œìŠ¤í…œ
        - **ì¬ìƒì—ë„ˆì§€ í™•ëŒ€**: í™”ì„ì—°ë£Œ ì¤‘ì‹¬ì—ì„œ ì¬ìƒì—ë„ˆì§€ ì¤‘ì‹¬ ì „í™˜ í•„ìš”
        - **ì§€ì†ê°€ëŠ¥í•œ ìƒí™œë°©ì‹**: ë¼ë²¨ ì—†ëŠ” ìƒí’ˆ, í…€ë¸”ëŸ¬ ê³µìœ  ì„œë¹„ìŠ¤ ë“± ìƒˆë¡œìš´ ì‹œë„
        """)

# ë©”ì¸ í™”ë©´
st.title("ğŸŒ ê¸°í›„ ìœ„ê¸° ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„± í™œë™ ë„ìš°ë¯¸")

# í•™ìƒ ì •ë³´ ì…ë ¥ í¼
if not st.session_state.student_info_submitted:
    with st.form("student_info_form"):
        st.subheader("í•™ìƒ ì •ë³´ ì…ë ¥")
        col1, col2 = st.columns(2)
        with col1:
            student_name = st.text_input("ì´ë¦„")
        with col2:
            student_id = st.text_input("í•™ë²ˆ")

        submitted = st.form_submit_button("ë¡œê·¸ì¸")
        if submitted and student_name and student_id:
            st.session_state.student_name = student_name
            st.session_state.student_id = student_id
            st.session_state.student_info_submitted = True

            # í•™ìƒ ì •ë³´ ì €ì¥
            student_info = {
                "session_id": st.session_state.session_id,
                "student_name": student_name,
                "student_id": student_id,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "type": "student_info"
            }

            # ë°ì´í„° ì €ì¥
            save_data(student_info)

            # ì›°ì»´ ë©”ì‹œì§€ ì¶”ê°€
            welcome_message = {
                "role": "assistant",
                "content": f"""ì•ˆë…•í•˜ì„¸ìš”, {student_name} í•™ìƒ! ê¸°í›„ ìœ„ê¸° ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±ì„ ë„ì™€ë“œë¦´ê²Œìš”.
ì €ëŠ” ìŠ¤í† ë¦¬ë³´ë“œ ëª¨ë‘ í™œë™, ê°œë³„í™œë™, ë°œí‘œì¤€ë¹„ì— ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.
ê·¸ë¦¬ê³  ì—¬ëŸ¬ë¶„ì´ ë§Œë“¤ ìŠ¤í† ë¦¬ë³´ë“œëŠ” ê¸°í›„ ìœ„ê¸°ì— ê´€í•œ ì¤‘ìš”í•œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ëŠ” ë„êµ¬ê°€ ë  ê±°ì˜ˆìš”. 
ì–´ë–¤ ì•„ì´ë””ì–´ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹ ê°€ìš”?

ì˜ˆë¥¼ ë“¤ì–´:
- ì–´ë–¤ ì£¼ì œë¡œ í•˜ëŠ” ê²ƒì´ ì¢‹ì„ê¹Œ?
- ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ìŠ¤í† ë¦¬ë³´ë“œë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? (ì§§ì€ ë§Œí™”, ì‹œë‚˜ë¦¬ì˜¤, ê´‘ê³  ë“±)
- ìŠ¤í† ë¦¬ë³´ë“œì— í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ” ë‚´ìš©ì€ ë¬´ì—‡ì¼ê¹Œ?
- ìŠ¤í† ë¦¬ë³´ë“œì— ì–´ë–¤ ìºë¦­í„°ë‚˜ ìƒí™©ì„ í¬í•¨ì‹œí‚¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
- ë°œí‘œí•  ë•Œì—ëŠ” ì–´ë–¤ ì ì„ ìœ„ì£¼ë¡œ ë°œí‘œí•˜ë©´ ì¢‹ì„ê¹Œ?

ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ê±°ë‚˜ ì•„ì´ë””ì–´ë¥¼ ë‚˜ëˆ ì£¼ì„¸ìš”!
"""
            }
            st.session_state.messages.append(welcome_message)

            # ì›°ì»´ ë©”ì‹œì§€ë„ ì €ì¥
            welcome_data = {
                "session_id": st.session_state.session_id,
                "student_name": student_name,
                "student_id": student_id,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "type": "assistant_message",
                "content": welcome_message["content"]
            }
            save_data(welcome_data)

            st.rerun()

    # í•™ìƒ ì •ë³´ê°€ ì…ë ¥ë˜ì§€ ì•Šì€ ê²½ìš° ì¶”ê°€ ë‚´ìš© í‘œì‹œí•˜ì§€ ì•ŠìŒ
    st.info("ìœ„ì˜ í•™ìƒ ì •ë³´ë¥¼ ì…ë ¥í•˜ì‹  í›„ ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# í•™ìƒ ì •ë³´ê°€ ì œì¶œëœ ê²½ìš°ì—ë§Œ ì±— ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ
elif st.session_state.student_info_submitted:
    # í”¼ë“œë°± ëª¨ë“œì¸ ê²½ìš°
    if st.session_state.feedback_mode:
        st.subheader("ìŠ¤í† ë¦¬ë³´ë“œ í”¼ë“œë°±")

        # ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°± ìš”ì²­
        with st.spinner("í”¼ë“œë°±ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ë¶„ì„ ë° í”¼ë“œë°±
            feedback_prompt = """ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚´ ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì—…ì— ëŒ€í•´ ë‹¤ìŒ í•­ëª©ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:
            1. ìˆ˜í–‰í‰ê°€ì™€ ê´€ë ¨ë˜ì–´ ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ì˜ ìˆ˜ì™€ ì§ˆ (í‰ê°€ ê¸°ì¤€ì— ë”°ë¥¸ í˜„ì¬ ë“±ê¸‰)
            2. ìŠ¤í† ë¦¬ë³´ë“œì˜ ê¸°í›„ ìœ„ê¸° ê´€ë ¨ì„±
            3. ê°œì„ í•  ì ê³¼ ê°•í™”í•  ì 
            4. ë°œí‘œ ì‹œ í•µì‹¬ì ìœ¼ë¡œ ê°•ì¡°í•´ì•¼ í•  ë©”ì‹œì§€

            í”¼ë“œë°±ì€ êµ¬ì²´ì ì´ê³  ê±´ì„¤ì ì´ë©° ê²©ë ¤í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

            # í”¼ë“œë°± ìƒì„±ì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±
            feedback_messages = [m for m in st.session_state.messages]
            feedback_messages.append({"role": "user", "content": feedback_prompt})

            # GPT-4ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë“œë°± ìƒì„± (ë” ë†’ì€ í’ˆì§ˆì˜ í”¼ë“œë°±ì„ ìœ„í•´)
            feedback = get_gpt_response(feedback_messages, use_gpt4=True)

            # í”¼ë“œë°± í‘œì‹œ
            st.markdown(f"### í”¼ë“œë°± ê²°ê³¼\n{feedback}")

            # í”¼ë“œë°± ê¸°ë¡
            feedback_data = {
                "session_id": st.session_state.session_id,
                "student_name": st.session_state.student_name,
                "student_id": st.session_state.student_id,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "type": "feedback",
                "content": feedback
            }

            # ë°ì´í„° ì €ì¥
            save_data(feedback_data)

        # í”¼ë“œë°± ëª¨ë“œ ì¢…ë£Œ ë²„íŠ¼
        if st.button("ìŠ¤í† ë¦¬ë³´ë“œ ì‘ì„±ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            st.session_state.feedback_mode = False
            st.rerun()

    # ì¼ë°˜ ì±„íŒ… ëª¨ë“œ
    else:
        # ë©”ì‹œì§€ ê¸°ë¡ í‘œì‹œ
        for msg in st.session_state.messages:
            if msg["role"] != "system":  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
                if msg["role"] == "assistant":
                    with st.chat_message("assistant"):
                        st.markdown(msg["content"])
                elif msg["role"] == "user":
                    with st.chat_message("user"):
                        st.markdown(msg["content"])

        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        user_input = st.chat_input("ìŠ¤í† ë¦¬ë³´ë“œì— ëŒ€í•´ ì§ˆë¬¸í•˜ê±°ë‚˜ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

        if user_input:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": user_input})
            with st.chat_message("user"):
                st.markdown(user_input)

            # ì…ë ¥ ì‹œê°„ ê¸°ë¡
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # ëŒ€í™” ë¡œê·¸ ì €ì¥
            chat_log = {
                "session_id": st.session_state.session_id,
                "student_name": st.session_state.student_name,
                "student_id": st.session_state.student_id,
                "timestamp": current_time,
                "type": "user_message",
                "content": user_input
            }

            # ë°ì´í„° ì €ì¥
            save_data(chat_log)

            # GPT ì‘ë‹µ ìƒì„± (ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
            with st.spinner("ì‘ë‹µì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                messages_for_api = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
                response = get_gpt_response(messages_for_api, use_gpt4=False)

            # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"):
                st.markdown(response)

            # ì‘ë‹µ ë¡œê·¸ ì €ì¥
            response_log = {
                "session_id": st.session_state.session_id,
                "student_name": st.session_state.student_name,
                "student_id": st.session_state.student_id,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "type": "assistant_message",
                "content": response
            }

            # ë°ì´í„° ì €ì¥
            save_data(response_log)

# ê´€ë¦¬ì ëª¨ë“œ (ìˆ¨ê²¨ì§„ ê¸°ëŠ¥) - URLì— ?admin=true ì¶”ê°€ ì‹œ ì ‘ê·¼ ê°€ëŠ¥
if st.query_params.get("admin", "false") == "true":
    st.markdown("---")
    st.header("ğŸ‘¨â€ğŸ« ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ")

    # API ì‚¬ìš© í†µê³„
    st.metric("ì´ API í˜¸ì¶œ íšŸìˆ˜", st.session_state.api_call_count)

    # íƒ­ ìƒì„±
    admin_tab1, admin_tab2, admin_tab3, admin_tab4 = st.tabs(["í•™ìƒ ëª©ë¡", "ëŒ€í™” ë‚´ìš©", "ë°ì´í„° ë¶„ì„", "ë°±ì—… ë‹¤ìš´ë¡œë“œ"])

    with admin_tab1:
        st.subheader("ë“±ë¡ëœ í•™ìƒ ëª©ë¡")

        # í•™ìƒ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
        try:
            with open(STUDENTS_FILE, 'r', encoding='utf-8') as f:
                students = json.load(f)

            if students:
                # í•™ìƒ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                student_df = pd.DataFrame(students)
                st.dataframe(student_df)

                # í•™ìƒ ìˆ˜ í‘œì‹œ
                st.info(f"ì´ {len(students)}ëª…ì˜ í•™ìƒì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

                # í•™ìƒ ì •ë³´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv = student_df.to_csv(index=False)
                st.download_button(
                    label="í•™ìƒ ëª©ë¡ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv,
                    file_name="í•™ìƒëª©ë¡.csv",
                    mime="text/csv"
                )
            else:
                st.info("ì•„ì§ ë“±ë¡ëœ í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"í•™ìƒ ì •ë³´ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    with admin_tab2:
        st.subheader("í•™ìƒë³„ ëŒ€í™” ë‚´ìš©")

        # í•™ìƒ ì„ íƒ ë“œë¡­ë‹¤ìš´
        try:
            with open(STUDENTS_FILE, 'r', encoding='utf-8') as f:
                students = json.load(f)

            if students:
                student_options = [f"{s['student_name']} ({s['student_id']})" for s in students]
                selected_student = st.selectbox("í•™ìƒ ì„ íƒ", options=student_options)

                # ì„ íƒí•œ í•™ìƒì˜ ì •ë³´ ì°¾ê¸°
                selected_name, selected_id = selected_student.split(" (")
                selected_id = selected_id.rstrip(")")

                # ëŒ€í™” íŒŒì¼ ì°¾ê¸° (íŒŒì¼ëª… í˜•ì‹: í•™ë²ˆ_ì´ë¦„.json)
                conversation_file = os.path.join(CONVERSATIONS_DIR, f"{selected_id}_{selected_name}.json")

                if os.path.exists(conversation_file):
                    with open(conversation_file, 'r', encoding='utf-8') as f:
                        conversation = json.load(f)

                    # ëŒ€í™” ë‚´ìš© í‘œì‹œ
                    for msg in conversation["messages"]:
                        if msg["role"] == "user":
                            st.info(f"**í•™ìƒ ({msg['timestamp']}):**\n{msg['content']}")
                        elif msg["role"] == "assistant":
                            st.success(f"**AI ({msg['timestamp']}):**\n{msg['content']}")

                    # í”¼ë“œë°± í‘œì‹œ
                    if "feedback" in conversation and conversation["feedback"]:
                        st.subheader("í”¼ë“œë°± ê¸°ë¡")
                        for feedback in conversation["feedback"]:
                            st.warning(f"**í”¼ë“œë°± ({feedback['timestamp']}):**\n{feedback['content']}")

                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    conversation_json = json.dumps(conversation, ensure_ascii=False, indent=2)
                    st.download_button(
                        label="ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ (JSON)",
                        data=conversation_json,
                        file_name=f"{selected_id}_{selected_name}_ëŒ€í™”.json",
                        mime="application/json"
                    )
                else:
                    st.error(f"ëŒ€í™” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {conversation_file}")
            else:
                st.info("ì•„ì§ ë“±ë¡ëœ í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ëŒ€í™” ë‚´ìš© ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    with admin_tab3:
        st.subheader("ë°ì´í„° ë¶„ì„")

        # ì „ì²´ ë°ì´í„° ë¶„ì„
        try:
            # ëª¨ë“  ëŒ€í™” íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
            all_conversations = []
            for filename in os.listdir(CONVERSATIONS_DIR):
                if filename.endswith('.json'):
                    file_path = os.path.join(CONVERSATIONS_DIR, filename)
                    with open(file_path, 'r', encoding='utf-8') as f:
                        conversation = json.load(f)
                        all_conversations.append(conversation)
            
            if all_conversations:
                # ë¶„ì„ ë°©ë²• ì„ íƒ
                analysis_method = st.radio(
                    "ë¶„ì„ ë°©ë²• ì„ íƒ:",
                    ["ë¹ ë¥¸ ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)", "ì •ë°€ ë¶„ì„ (GPT í™œìš©)"],
                    help="ì •ë°€ ë¶„ì„ì€ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•˜ì§€ë§Œ ì‹œê°„ì´ ë” ê±¸ë¦½ë‹ˆë‹¤."
                )
                
                if analysis_method == "ì •ë°€ ë¶„ì„ (GPT í™œìš©)":
                    # GPT ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
                    if st.button("GPT ë¶„ì„ ì‹œì‘", type="primary"):
                        # ì§„í–‰ ìƒí™© í‘œì‹œ
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        def update_progress(current, total):
                            progress = current / total
                            progress_bar.progress(progress)
                            status_text.text(f'ë¶„ì„ ì§„í–‰ ì¤‘... {current}/{total} ({progress:.1%})')
                        
                        # GPT ë¶„ì„ ì‹¤í–‰
                        with st.spinner("GPTë¥¼ í™œìš©í•œ ì •ë°€ ë¶„ì„ ì¤‘..."):
                            student_message_data = analyze_conversations_with_gpt(
                                all_conversations, 
                                progress_callback=update_progress
                            )
                        
                        # ì§„í–‰ ìƒí™© ì •ë¦¬
                        progress_bar.empty()
                        status_text.text("ë¶„ì„ ì™„ë£Œ!")
                        
                        # ì„¸ì…˜ì— ê²°ê³¼ ì €ì¥
                        st.session_state.gpt_analysis_result = student_message_data
                    
                    # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
                    if hasattr(st.session_state, 'gpt_analysis_result'):
                        student_message_data = st.session_state.gpt_analysis_result
                        
                        # í”„ë¡¬í”„íŠ¸ ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ í‰ê°€ í•¨ìˆ˜
                        def evaluate_grade(prompt_count):
                            if prompt_count >= 5:
                                return "A (40ì )"
                            elif prompt_count == 4:
                                return "B (35ì )"  
                            elif prompt_count == 3:
                                return "C (30ì )"
                            elif prompt_count == 2:
                                return "D (25ì )"
                            else:
                                return "E (20ì )"
                        
                        # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ë“±ê¸‰ ì¶”ê°€
                        student_df = pd.DataFrame(student_message_data)
                        student_df["ì˜ˆìƒ ë“±ê¸‰"] = student_df["ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜"].apply(evaluate_grade)
                        
                        # ê¸°ë³¸ í†µê³„ í‘œì‹œ
                        st.subheader("GPT ë¶„ì„ ê²°ê³¼")
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            avg_relevant = student_df["ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜"].mean()
                            st.metric("í‰ê·  ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜", f"{avg_relevant:.1f}")
                        with col2:
                            avg_total = student_df["ì „ì²´ ë©”ì‹œì§€ ìˆ˜"].mean()
                            st.metric("í‰ê·  ì „ì²´ ë©”ì‹œì§€ ìˆ˜", f"{avg_total:.1f}")
                        with col3:
                            relevance_rate = (student_df["ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜"].sum() / student_df["ì „ì²´ ë©”ì‹œì§€ ìˆ˜"].sum()) * 100
                            st.metric("ì „ì²´ ê´€ë ¨ë„", f"{relevance_rate:.1f}%")
                        
                        # ìƒì„¸ ë¶„ì„ í…Œì´ë¸”
                        st.subheader("í•™ìƒë³„ ìƒì„¸ ë¶„ì„")
                        st.dataframe(
                            student_df.sort_values(by="ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜", ascending=False),
                            use_container_width=True
                        )
                        
                        # ë“±ê¸‰ ë¶„í¬ ì°¨íŠ¸
                        st.subheader("ë“±ê¸‰ ë¶„í¬ (GPT ë¶„ì„ ê¸°ì¤€)")
                        grade_counts = student_df["ì˜ˆìƒ ë“±ê¸‰"].value_counts().reset_index()
                        grade_counts.columns = ["ë“±ê¸‰", "í•™ìƒ ìˆ˜"]
                        st.bar_chart(grade_counts.set_index("ë“±ê¸‰"))
                        
                        # ê´€ë ¨ë„ ë¶„ì„ ì°¨íŠ¸
                        st.subheader("í•™ìƒë³„ í”„ë¡¬í”„íŠ¸ ê´€ë ¨ë„")
                        chart_data = student_df[["í•™ìƒëª…", "ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ìˆ˜", "ì „ì²´ ë©”ì‹œì§€ ìˆ˜"]].head(10)
                        st.bar_chart(chart_data.set_index("í•™ìƒëª…"))
                        
                        # GPT ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                        csv_gpt = student_df.to_csv(index=False)
                        st.download_button(
                            label="GPT ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                            data=csv_gpt,
                            file_name="GPT_ë¶„ì„_ê²°ê³¼.csv",
                            mime="text/csv"
                        )
                        
                    else:
                        st.info("ğŸ‘† ìœ„ì˜ 'GPT ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì •ë°€ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
                
                else:
                    # ê¸°ì¡´ ë¹ ë¥¸ ë¶„ì„ ë°©ì‹
                    total_messages = sum(len(conv["messages"]) for conv in all_conversations)
                    user_messages = sum(
                        sum(1 for msg in conv["messages"] if msg["role"] == "user") for conv in all_conversations)
                    assistant_messages = sum(
                        sum(1 for msg in conv["messages"] if msg["role"] == "assistant") for conv in all_conversations)

                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ ë©”ì‹œì§€ ìˆ˜", total_messages)
                    with col2:
                        st.metric("í•™ìƒ ë©”ì‹œì§€ ìˆ˜", user_messages)
                    with col3:
                        st.metric("AI ì‘ë‹µ ìˆ˜", assistant_messages)

                    # ê¸°ì¡´ ë¶„ì„ ë¡œì§ (ê°„ë‹¨í•œ ë©”ì‹œì§€ ìˆ˜ ê¸°ë°˜)
                    student_message_data = []
                    for conv in all_conversations:
                        student_name = conv["student_name"]
                        student_id = conv["student_id"]
                        user_msg_count = sum(1 for msg in conv["messages"] if msg["role"] == "user")
                        assistant_msg_count = sum(1 for msg in conv["messages"] if msg["role"] == "assistant")

                        if conv["messages"]:
                            first_msg_time = datetime.strptime(conv["messages"][0]["timestamp"], "%Y-%m-%d %H:%M:%S")
                            last_msg_time = datetime.strptime(conv["messages"][-1]["timestamp"], "%Y-%m-%d %H:%M:%S")
                            duration = (last_msg_time - first_msg_time).total_seconds() / 60
                        else:
                            duration = 0

                        has_feedback = "feedback" in conv and len(conv["feedback"]) > 0

                        student_message_data.append({
                            "í•™ìƒëª…": student_name,
                            "í•™ë²ˆ": student_id,
                            "í•™ìƒ ë©”ì‹œì§€ ìˆ˜": user_msg_count,
                            "AI ì‘ë‹µ ìˆ˜": assistant_msg_count,
                            "ëŒ€í™” ì‹œê°„(ë¶„)": round(duration, 1),
                            "í”¼ë“œë°± ì—¬ë¶€": "O" if has_feedback else "X"
                        })

                    # ê¸°ì¡´ í‰ê°€ í•¨ìˆ˜
                    def evaluate_grade_simple(prompt_count):
                        if prompt_count >= 5:
                            return "A (40ì )"
                        elif prompt_count == 4:
                            return "B (35ì )"
                        elif prompt_count == 3:
                            return "C (30ì )"
                        elif prompt_count == 2:
                            return "D (25ì )"
                        else:
                            return "E (20ì )"

                    student_df = pd.DataFrame(student_message_data)
                    student_df["ì˜ˆìƒ ë“±ê¸‰"] = student_df["í•™ìƒ ë©”ì‹œì§€ ìˆ˜"].apply(evaluate_grade_simple)

                    st.subheader("í•™ìƒë³„ ê¸°ë³¸ ë¶„ì„ (ë©”ì‹œì§€ ìˆ˜ ê¸°ì¤€)")
                    st.dataframe(student_df)
                    
                    # ê¸°ì¡´ ì°¨íŠ¸ë“¤
                    st.subheader("í•™ìƒë³„ ë©”ì‹œì§€ ìˆ˜ ë¶„í¬")
                    top_students = student_df.sort_values(by="í•™ìƒ ë©”ì‹œì§€ ìˆ˜", ascending=False).head(10)
                    chart_data = pd.DataFrame({
                        "í•™ìƒ": top_students["í•™ìƒëª…"],
                        "í•™ìƒ ë©”ì‹œì§€": top_students["í•™ìƒ ë©”ì‹œì§€ ìˆ˜"],
                        "AI ì‘ë‹µ": top_students["AI ì‘ë‹µ ìˆ˜"]
                    })
                    st.bar_chart(chart_data.set_index("í•™ìƒ"))

                    # ë“±ê¸‰ ë¶„í¬
                    st.subheader("ë“±ê¸‰ ë¶„í¬ (ê¸°ë³¸ ë¶„ì„)")
                    grade_counts = student_df["ì˜ˆìƒ ë“±ê¸‰"].value_counts().reset_index()
                    grade_counts.columns = ["ë“±ê¸‰", "í•™ìƒ ìˆ˜"]
                    st.bar_chart(grade_counts.set_index("ë“±ê¸‰"))

                    # ê¸°ë³¸ ë¶„ì„ ë‹¤ìš´ë¡œë“œ
                    csv_basic = student_df.to_csv(index=False)
                    st.download_button(
                        label="ê¸°ë³¸ ë¶„ì„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv_basic,
                        file_name="ê¸°ë³¸_ë¶„ì„ë°ì´í„°.csv",
                        mime="text/csv"
                    )

                # í‚¤ì›Œë“œ ë¶„ì„ì€ ê³µí†µìœ¼ë¡œ ìœ ì§€
                st.subheader("ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œ ë¶„ì„")
                # ... ê¸°ì¡´ í‚¤ì›Œë“œ ë¶„ì„ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€ ...
                
            else:
                st.info("ë¶„ì„í•  ëŒ€í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            
            
    with admin_tab4:
        st.subheader("ì „ì²´ ë°ì´í„° ë°±ì—…")
        
        if st.button("ëª¨ë“  ë°ì´í„° ZIPìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"):
            import zipfile
            import io
            
            # ë©”ëª¨ë¦¬ì— ZIP íŒŒì¼ ìƒì„±
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # í•™ìƒ ì •ë³´ íŒŒì¼ ì¶”ê°€
                if os.path.exists(STUDENTS_FILE):
                    with open(STUDENTS_FILE, 'r', encoding='utf-8') as f:
                        zipf.writestr("students.json", f.read())
                
                # ëŒ€í™” íŒŒì¼ ì¶”ê°€
                for filename in os.listdir(CONVERSATIONS_DIR):
                    if filename.endswith('.json'):
                        file_path = os.path.join(CONVERSATIONS_DIR, filename)
                        with open(file_path, 'r', encoding='utf-8') as f:
                            zipf.writestr(f"conversations/{filename}", f.read())
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
            zip_buffer.seek(0)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            st.download_button(
                label="ë°ì´í„° ë°±ì—… ë‹¤ìš´ë¡œë“œ",
                data=zip_buffer,
                file_name=f"storyboard_data_backup_{timestamp}.zip",
                mime="application/zip"
            )
            
            st.success("ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì••ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë°±ì—… íŒŒì¼ì„ ì €ì¥í•˜ì„¸ìš”.")
